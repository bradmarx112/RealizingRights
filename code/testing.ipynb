{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14102\\Brown\\Realizing_Rights\\RealizingRights\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.web_utils import recurse_scan_all_unique_links_in_site, closest_link_match, make_https, prepend_root_to_url, make_driver_utils\n",
    "from url_scraper.link_data import LinkData\n",
    "from objects.scrape_lists import blacklist_terms, link_keywords, board_meeting_keywords, social_media_sites\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14102\\anaconda3\\envs\\real_right_env\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "district_df = pd.read_excel(io='data/USSchoolDistrictWebsiteInfo.xlsx', sheet_name='ELSI Export', header=6)\n",
    "district_df['URL'] = district_df['URL'].apply(lambda x: make_https(url=x))\n",
    "\n",
    "district_df['NumStudents'] = pd.to_numeric(district_df['NumStudents'], errors='coerce')\n",
    "district_df_with_urls = district_df[~district_df['URL'].isna()]\n",
    "district_df_with_urls['URL'] = district_df_with_urls['URL'].apply(lambda x: prepend_root_to_url(base_url=x.lower(), prefix=''))\n",
    "district_df_with_urls = district_df_with_urls[district_df_with_urls['NumStudents'] > 0]\n",
    "district_df_with_urls = district_df_with_urls[district_df_with_urls['NumSchools'] > 0].reset_index(drop=True)\n",
    "district_df_with_urls.sort_values(by='NumStudents', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'youtube': 0, 'facebook': 0, 'twitter': 0, 'vimeo': 2} Video: https://lausd.wistia.com/medias/mkguffmxty\n",
      "{} None\n",
      "{} None\n",
      "{'twitter': 0, 'facebook': 0} None\n",
      "{'twitter': 0, 'youtube': 0, 'facebook': 0} Board Meetings & Workshops: https://www.browardschools.com/boardmeetings\n",
      "{'twitter': 0, 'facebook': 0, 'youtube': 0} Minutes: https://www.hillsboroughschools.org/domain/5433\n",
      "{} None\n",
      "{'youtube': 0, 'twitter': 0, 'facebook': 0} Board: https://www.houstonisd.org/domain/40263\n",
      "{'twitter': 0, 'youtube': 0, 'facebook': 0} Board Meetings: https://www.palmbeachschools.org/domain/255\n",
      "{'facebook': 0, 'twitter': 0, 'youtube': 0} School Board Meetings: https://www.fcps.edu/school-board/school-board-meetings\n"
     ]
    }
   ],
   "source": [
    "drvr, actions, wait = make_driver_utils()\n",
    "\n",
    "url_data = {}\n",
    "for _, row in district_df_with_urls[:100].iterrows():\n",
    "\n",
    "    url = row['URL']\n",
    "    start_link_set = set()\n",
    "    dist_info = []\n",
    "    start_link_set.add(LinkData(link_text='BASE', link_url=url, depth=0))\n",
    "    recursed_lcl_links, recursed_ext_links = set(), set()\n",
    "    recursed_lcl_links, recursed_ext_links = recurse_scan_all_unique_links_in_site(url=url,\n",
    "                                                                                    base_url=url, \n",
    "                                                                                    local_link_set=start_link_set,\n",
    "                                                                                    external_link_set=set(),\n",
    "                                                                                    drvr=drvr, \n",
    "                                                                                    actions=actions,\n",
    "                                                                                    blacklist_terms=blacklist_terms,\n",
    "                                                                                    wait=wait,\n",
    "                                                                                    link_keywords=link_keywords)\n",
    "\n",
    "    cur_sim = 60\n",
    "    best_link = None\n",
    "    lcl_links_sorted = sorted(list(recursed_lcl_links), key=lambda x: x.depth_found)\n",
    "    ext_links_sorted = sorted(list(recursed_ext_links), key=lambda x: x.depth_found)\n",
    "    for lcl_link in lcl_links_sorted:\n",
    "        if cur_sim == 100:\n",
    "            break\n",
    "        sim = closest_link_match(lcl_link.link_text, board_meeting_keywords)\n",
    "        if sim > cur_sim:\n",
    "            best_link = lcl_link\n",
    "            cur_sim = sim\n",
    "\n",
    "    for ext_link in ext_links_sorted:\n",
    "        if cur_sim == 100:\n",
    "            break\n",
    "        if ext_link.link_text:\n",
    "            sim = closest_link_match(ext_link.link_text, board_meeting_keywords)\n",
    "            if sim > cur_sim:\n",
    "                best_link = ext_link\n",
    "                cur_sim = sim\n",
    "\n",
    "    # Identify External Links Pointing to social media sites \n",
    "    sites_identified = {}\n",
    "    num_ext_links = len(ext_links_sorted)\n",
    "    ext_id = 0\n",
    "    social_media_sites = ['youtube', 'vimeo', 'facebook', 'twitter']\n",
    "    while ext_id < num_ext_links:\n",
    "        ext_link = ext_links_sorted[ext_id]\n",
    "        scl_id = 0\n",
    "        while scl_id < len(social_media_sites):\n",
    "            if social_media_sites[scl_id] in ext_link.link_url:\n",
    "                sites_identified[social_media_sites.pop(scl_id)] = ext_link.depth_found\n",
    "            scl_id += 1\n",
    "\n",
    "        ext_id += 1\n",
    "\n",
    "        if len(social_media_sites) == 0:\n",
    "            break\n",
    "    \n",
    "    if best_link:\n",
    "        url_data[row['Agency ID']] = (sites_identified, best_link.link_text, best_link.link_url, best_link.depth_found)\n",
    "    else: \n",
    "        url_data[row['Agency ID']] = (sites_identified, None, None, None)\n",
    "    print(sites_identified, best_link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['District ID', 'brd_mtn_URL_text', 'brd_mtn_URL_Link', 'brd_mtn_URL_depth', 'facebook', 'youtube', 'twitter', 'vimeo'])\n",
    "\n",
    "\n",
    "for url, data in url_data.items():\n",
    "    row = {\n",
    "        'District ID': url,\n",
    "        'brd_mtn_URL_text': data[1],\n",
    "        'brd_mtn_URL_Link': data[2],\n",
    "        'brd_mtn_URL_depth': data[3],\n",
    "        'facebook': None,\n",
    "        'youtube': None,\n",
    "        'twitter': None,\n",
    "        'vimeo': None\n",
    "    }\n",
    "\n",
    "    if data[0]:\n",
    "        row.update(data[0])\n",
    "\n",
    "    df = df.append(row, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_dist_df = df.merge(district_df_with_urls, left_on='District ID', right_on='Agency ID')\n",
    "scanned_dist_df.to_csv('data/SampleOutput.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9c5d8b2ff7cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistrict_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/USSchoolDistrictWebsiteInfo.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ELSI Export'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdistrict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NumStudents'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistrict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NumStudents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdistrict_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NumStudents'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "district_df = pd.read_excel(io='data/USSchoolDistrictWebsiteInfo.xlsx', sheet_name='ELSI Export', header=6)\n",
    "district_df['NumStudents'] = pd.to_numeric(district_df['NumStudents'], errors='coerce')\n",
    "district_df.sort_values(by='NumStudents', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['District ID',\n",
       " 'brd_mtn_URL_text',\n",
       " 'brd_mtn_URL_Link',\n",
       " 'brd_mtn_URL_depth',\n",
       " 'youtube',\n",
       " 'vimeo',\n",
       " 'facebook',\n",
       " 'twitter']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['District ID', 'brd_mtn_URL_text', 'brd_mtn_URL_Link', 'brd_mtn_URL_depth']\n",
    "\n",
    "columns + social_media_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real_right_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
